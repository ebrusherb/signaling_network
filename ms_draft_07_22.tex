\documentclass{article}
\usepackage{latexsym}
\usepackage{amssymb,amsmath}
\usepackage{custom2}
\usepackage{graphicx} % for figures
\usepackage{epstopdf} % so can use EPS or PDF figures
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{booktabs}
\usepackage[pdftex]{hyperref}
\usepackage{lscape}
\usepackage{xcolor}
\usepackage{natbib}

\captionsetup{justification=RaggedRight, singlelinecheck=false}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcommand{\argmax}{\text{argmax}}
\newcommand{\Tr}{\text{Tr}}
%\newtheorem{claim}{Claim}
\newtheorem{ass}{Assumption}

\addtolength{\evensidemargin}{-.5in}
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\textwidth}{1.4in}
\addtolength{\textheight}{1.4in}
\addtolength{\topmargin}{-.5in}

\pagestyle{empty}

\begin{document}
\begin{center}
\Large

\end{center}


\vspace{0pt}

\begin{center}
{\bf \LARGE{Conflict and Strategy in Collective Computation (???)}}
\end{center}

\section{Abstract}
In neural and social systems, an individual's position in an interaction network can be informative about its function within the group. The development of the network and scores given by each node's position is a collective computation whose output is available to group members.  For example, in social groups, power is defined as the degree of consensus in the network about each node's value. We use a leaky integrator model for a noisy decision process that gives the direction and magnitude of each edge in the network. We find that differences in the model when it is applied to neural and social systems do not affect the accuracy of decisions. We find that a group of individuals prioritizing personal preference over accuracy make more accurate decisions. We find that when pairwise decisions are accurate, local properties of the network are the most informative, but when accuracy decreases global properties are more informative. Finally, we find that the shape of the distribution of power is determined by waiting costs of those decisions. Our model can be applied to a number of systems and our results suggest that conflict and strategy are important in the collective computations performed by all of them.

\section{Keywords }
collective computation, noisy learning, leaky integrator, decisions, social network, consensus, power, social structure

\section{Introduction} 

When individuals come together in groups, their computational abilities can be combined in nonlinear ways, giving rise to collective computations that are better than would be expected from the individuals' abilities (ref XXX).  This collective computation cannot be decomposed into parts that are caused or performed by individuals. In schools and flocks, the group can sense its environment and navigate more accurately than any of its individual members can (ref XXX).  Similarly, a group of quorum sensing bacteria can change their behavior, for example color or phosphorescence, based on the properties of the environment that no individual cell would be able to detect (ref XXX). The brain performs computations and makes decisions of which no individual neuron would be capable (ref XXX). Social groups of animals create social structures, which provide information about their members to which no individual would otherwise have access \cite{Flack:2004oq,Flack:2006fk,Flack:2006uq}. As external observers to these systems, the integration of individual behaviors into a performance that is much greater than the sum of its parts can seem an amazing feat. To the members of the systems, for example birds in a flock or monkeys in a social group, the group level output can be a new source of information and can be used to make decisions about how to behave.

Some of these collective computations rely on an interaction network between the individual members of the group. There are many measurements of position in a network that assign a value to each node, for example a node's in-degree or centrality within the network.  Any of these can be thought of as a collective computation, a group level output that depends on the structure of the network and whose dependence on any individual behavior is difficult to describe.  If each individual in the group has a functional role or value, as well as a position in the interaction network, then a useful collective computation would give individuals scores that are informative about these underlying values.

An animal's power is defined as the degree of consensus in its group about its fighting ability and the distribution of these power scores is referred to as the power structure \cite{Brush:2013fk,Flack:2004oq,Flack:2006uq,Preuschoft:2004ly}. In macaques, power is a useful variable since it reflects the animals' true abilities and the animals themselves do use estimates of their peers' and their own power to decide how to behave \cite{Flack:2004oq,Flack:2006fk,Flack:2006uq}.  In pigtailed macaques, the animals have a stereotyped signal, a formal subordination signal, that one animal will emit to another to communicate that it agrees to be subordinate \cite{Flack:2004oq,Flack:2006uq,Flack:2007kx,Preuschoft:2004ly}. Since a subordination signal indicates one animal believes another to have a higher fighting ability, a network of subordination signals can be used to determine the degree of consensus in the whole group about any individual's ability.  In previous work, we developed a number of network metrics to measure the degree of consensus in the group about each node \cite{Brush:2013fk,Flack:2006uq}.  We found a few that produced scores that were predictive of individuals' functional behaviors, which suggests they provide information about the animals' true fighting abilities.  This kind of consensus may be important in neural systems, as well.  A number of neural populations may respond to or encode different environmental stimuli or variables.  The consensus in a network of neural populations about the value of a number of environmental stimuli could help the brain make decisions about the relative values of many possibilities. 

In each of these systems, the individuals-- monkeys or neural populations-- are trying to learn and make decisions in a noisy environment.  In such a situation, an individual acquires evidence that may or may not reflect the true state of the environment and only makes a decision once it has acquired enough evidence to reduce its uncertainty sufficiently.  If the environment can be in one of the two possible states, the optimal way to decide between these alternatives is an algorithm called a sequential probability ratio test (SPRT) (ref XXX).  An individual using this learning method gathers a sequence of pieces of evidence that he uses to update his belief about the state of the world until this belief is strong enough to make a decision.  This updating process can equivalently be written as a set of stochastic differential equations (ref XXX), which are more flexible in allowing for memory loss.  This type of model, sometimes referred to as a leaky integrator model, is applicable to any system in which an individual gathers evidence and chooses the alternative for which he has gathered more support.

Noisy learning models can be used to model animal conflicts, and the SPRT has been previously used to describe animal conflicts over resources \citep{Froment:2010fk}. In a group of macaques, animals have different fighting abilities, and when a pair of animals engages in a fight, one animal is more likely on average to win.  Over time, as one animal learns that it is likely to lose fights, it will decide to emit the formal subordination signal, communicating its agreeing to the subordinate role in their relationship \citep{Flack:2007kx, Flack:2006fk,Flack:2004oq, Waal:1985fk,Caldecott:1986uk}.  The outcome of a fight is affected by the identity and presence of each animal's allies, motivation levels,  external environmental variables, and other factors.  Because of this stochasticity, the number of fights won and lost in any period of time is a random variable.  Each animal's opinion about its relative dominance, therefore, will perform a biased random walk until one animal's opinion of itself is low enough to agree to being subordinate, and this process can be describe by a leaky integrator model.

Leaky integrator models have been used to describe decision making in both monkeys and humans \citep{Eckhoff:2008uq, Brown:2005fk,Feng:2009kl,Bogacz:2006uq}.  Often an experimental subject is presented with a visual stimulus that consists of dots, some percentage of which are moving coherently either left or right and the rest of which are moving randomly.  The subject is then asked to decide the direction in which the dots are moving.  If there are two neural populations, each of which fires in response to a particular direction of motion, one firing rate will tend to increase and the other will tend to decrease, depending on the direction of the stimulus.  The random dots make the stimulus noisy and sometimes the firing rates will change in the wrong direction. Eventually, either the experimenter forces a decision to be made, in which case whichever population has a higher firing rate determines which decision is made, or the firing rate of one population becomes high enough that the subject decides for that direction.  In the model, the two decision variables--- the firing rates of two neural populations responding to left and right motion--- perform a biased random walk until enough evidence has been accumulated to make a decision one way or the other.  This model has successfully explained and predicted performance in a number of experiments \citep{Eckhoff:2008uq, Brown:2005fk,Feng:2009kl,Bogacz:2006uq}.  

The use of stochastic differential equations to model noisy learning has been rather phenomenological.  Here we turn a simple mechanistic description of the accumulation of information into a set of stochastic differential equations, making two simplifying assumptions about the timescales on which probabilistic events occur \cite{Gillespie:2000fk}. We then use this model to answer the following questions. Are there differences between decision making in the neural and social systems? What method of measuring position in an interaction network is the most informative about individuals' true values? How should individuals make decisions such that the resulting collective computation is most accurate? How is the shape of the power structure affected by how individuals make decisions? How well does our model describe empirical social systems?

\section{Model} 
\subsection{Stochastic differential equations }    
%% make debt to Gillespie clearer

There are two possible types of environmental evidence: in the neural system, a dot can move either left or right and in the social system, a fight can be won by one animal or another.  For clarity in the following we will refer to these left or right dots, but the biological interpretation of the two types of inputs depends on the system. There are two decision variables, $X_1$ and $X_2$. In the absence of any input, the decision variables leak back towards $0$ with rate $\ell$.  (A table of all variables used in the text is given in Table \ref{variables}.)  If there is no input, then over a period length $\tau$ a decision variable decreases as $X(t+\tau)=(1-\ell\tau)X(t)$.

Each decision variable responds positively to one type of input and negatively to the other.  In the neural case, one neural population responds positively to left dots and negatively to right dots and the other neural population does the opposite.  In the social case, one animal's estimate of its own dominance increases when it wins fights and decreases when it loses fights, and the other animal's estimate does the opposite. Neither decision variable has perfect memory.  Specifically, $X_1$ increases by a boost $b$ when it sees a left dot and decrements by $-b$ when it sees a right dot, and conversely for $X_2$.     
To calculate the variables at time $t+\tau$, we  count how many times each of type of input occurred in the time since $t$ and add the changes resulting from these events to the background leaky estimate (as in \cite{Gillespie:2000fk}):
\begin{align*}
X_1(t+\tau)&=(1-\ell\tau)X_1(t)+b\times\# \text{ of left dots in }[t,t+\tau)-b\times\# \text{ of right dots in }[t,t+\tau)
\\ X_2(t+\tau)&=(1-\ell\tau)X_2(t)-b\times\# \text{ of left dots in }[t,t+\tau)+b\times\# \text{ of right dots in }[t,t+\tau). 
\end{align*}

Our first assumption is that the rates at which the two types of inputs occur is constant over time.  We can thus describe the number of each type of event with a Poisson random variable, $N_\text{L}$ and $N_\text{R}$.  We rewrite our basic equations to give 
\begin{align*}
X_1(t+\tau)&=(1-\ell\tau)X_1(t)+bN_\text{L}-bN_\text{R}
\\ X_1(t+\tau)&=(1-\ell\tau)X_2(t)-bN_\text{L}+bN_\text{R}.
\end{align*}
If events happen at a rate $r$ and the event is a left dot with probability $c$ and a right dot with probability $1-c$, then the expectation of $N_L$ and $N_R$ in a period of length $\tau$ are, respectively, $\tau r c$ and $\tau r(1-c)$. In the neural case, $c$ is related to the ``coherence'' of the visual stimulus.  A $c$ close to $0$ or $1$ means that most of the events are of one type or the other and the decision is easier to make than when $c$ is close to $.5$.

If enough events happen in the period of time from $t$ to $t+\tau$ then we can approximate the Poisson random variables with Normal random variables with mean and variance equal to the mean of the Poisson random variables.  Our second assumption, then, is that the period of time of length $\tau$ is long enough to make this approximation. Let $Z_\text{L}$ and $Z_\text{R}$, be independent standard Normal random variables, i.e. with mean $0$ and standard deviation $1$.  Then our equations for $X_i(t+\tau)$ become
\begin{align*}
X_1(t+\tau)&=(1-\ell\tau)X_1(t)+b\bigg(\tau rc+\sqrt{\tau rc}Z_{\text{L}}\bigg)-b\bigg(\tau r(1-c)+\sqrt{\tau r(1-c)}Z_{\text{R}}\bigg)
\\X_2(t+\tau)&=(1-\ell\tau)X_2(t)-b\bigg(\tau rc+\sqrt{\tau rc}Z_{\text{L}}\bigg)+b\bigg(\tau r(1-c)+\sqrt{\tau r(1-c)}Z_{\text{R}}\bigg).
\end{align*}
Finally, as we make the period of time shorter and shorter, making $\tau$ infinitesimally small, these equations become stochastic differential equations,
\begin{equation}
\begin{array}{ll}
dX_1&=\bigg(-\ell X_1(t)+br(2c-1)\bigg)dt+\bigg(b\sqrt{rc}\bigg)dW_\text{L}t-\bigg(b\sqrt{r(1-c)}\bigg)dW_\text{R}t
\\dX_2&=\bigg(-\ell X_2(t)-br(2c-1)\bigg)dt-\bigg(b\sqrt{rc}\bigg)dW_\text{L}t+\bigg(b\sqrt{r(1-c)}\bigg)dW_\text{R}t
\end{array}
\end{equation}
where $dW_{\text{L}}$ and $dW_{\text{R}}$ are independent Brownian motions representing, respectively, the left and right inputs.  The assumptions about the timescales on which inputs occur are particularly reasonable in the social system, although the successful application of this type of model to neural populations implies they are not unreasonable in that system.  In Table \ref{variables}, we list the inputs, outputs, and variables of the decision model and how they should be interpreted in the neural and social systems.


\subsection{Reaching a decision }
Each decision variable, $X_1$ and $X_2$, accumulates information about the stimulus.  The sign and size of the two variables indicate how much evidence there is for each possible decision outcome.  When a lot of evidence for the first possibility has been observed, $X_1$ will be large and positive, and similarly for the second possibility.  If the difference in the variables can be observed, the difference indicates the relative strengths of the evidence for either possibility. If $Y=X_1-X_2$, when $Y$ is large enough the system decides on $X_1$ and when $Y$ is low enough the system decides on $X_2$.  Specifically, there are two thresholds, $T_2$ and $T_1$ such that if $Y>T_1$ the decision is for $X_1$ and if $Y<-T_2$ the decision is for $X_2$.  However, it may be the case that the difference in the variables cannot be observed.  In this case, the decision depends on whether $X_1$ or $X_2$ hits a threshold first.  Again, there are two thresholds, $T_2$ and $T_1$, and if $X_1<-T_1$ the decision is for $X_1$ and if the $X_2<-T_2$ the decision is for $X_2$. 

In the neural system, the two stochastic equations describing the activity of the two neural populations integrating environmental evidence are often reduced to the one-dimensional equation describing the difference in the activity levels to make the system easier to analyze \cite{Brown:2005fk,Bogacz:2006uq,Feng:2009kl}.  However, in the social system we are considering, we cannot make any assumptions about the existence of a third party evaluating the difference in the opinions of the two animals.  A ``decision," i.e. the emission of a signal from one of the two animals, is only reached when one of the two animals' opinions goes below a certain threshold.  The social system is therefore inherently two-dimensional, whereas the neural system may be adequately described by one dimension.  In Table \ref{differences}, we compare how the decision is made and how the decision process is optimized in the two systems.

\subsection{Utility of the decision }
The thresholds affect how long the decision takes and the probabilities with which each output is decided upon.  A good decision is one that reaches the correct output quickly, i.e. the expected time until a decision is reached (decision time, DT) and the probability that an incorrect decision is made (error rate, ER) are low.   However, it is impossible to minimize both simultaneously since waiting longer and accumulating more evidence makes the decision more accurate and conversely.  It may also be the case that each individual prefers one output over the other, regardless of which is ``correct''.  In the social case, an animal would prefer that its partner agreed to be subordinate, whether or not it is truly stronger.  In the neural case, different neural populations may receive different rewards if the decision reaches different outputs, regardless of which of the alternatives is ``true."  In these cases, a variable wants to maximize the probability that his preference is reached (probability of preference being chosen, $\text{PP}_i$).    

To describe the tradeoffs between error rate, decision time, and preference, we quantify the utility of the decision process by introducing three weights, $w_1$, $w_2$, and $w_3$ such that $w_1+w_2+w_3=1$.  These weights describe how the three quantities are prioritized.  For individual $i$, we define
\begin{equation*}
U_{i}=w_1\text{ER}+w_2\text{DT}+w_3(1-\text{PP}_i).
\end{equation*}
The decision is better if $U_i$ is lower.  In the social system, $w_2$ can be interpreted as the cost of fighting since when $w_2$ is higher, the time spent fighting until a decision is reached is more costly.  Similarly, $w_3$ can be interpreted as the benefit from being the dominant animal in a pair. In both cases, $w_3$ represents how stubborn the individuals are about their preferences. If $w_3\gneq 0$ and the individuals prefer different outcomes, neither can simultaneously be satisfied since $\text{PP}_1=1-\text{PP}_2$.

\subsection{Optimal thresholds }
An individual-- either a neural population or a monkey-- can be engaged in either a single decision or in many decisions at once.  In the social system, for example, an animal wants to decide whether it is dominant or subordinate to every other member of its social group.  For any pair of individuals, each has a utility, $U_1$ and $U_2$, and consequently each has a Nash equilibrium threshold such that, if they choose those thresholds, neither has an incentive to choose another.  Similarly, in a group of individuals, each individual $i$ has a utility $U_{ij}$ from its decision process with individual $j$.  His total utility is given by the average of these, $\langle U_{ij}\rangle _j$. These lead to an optimized set of thresholds such that no individual has an incentive to choose another threshold.

Since an individual is trying to use the same algorithm to learn about every one else, he is constrained to have only one decision threshold for each of these decision processes.  In order to consistently assign the difficulties with which all pairs in a group make decisions, we assign each individual a value $a_i$ and the difficulty with which the pair $i,j$ makes a decision increases with the difference in abilities, i.e. $c_{ij}$ is an increasing function of $|a_i-a_j|$. In the social system, these values can be interpreted as the fighting abilities of the animals.The optimal decision threshold in this group context depends on the distribution of difficulties ($c_{ij}$) of the decision an individual will have to make and the thresholds of the other individuals.    

 We use the following procedure to find optimal thresholds as a function of position in the group.  We repeatedly draw a set of fighting abilities from a uniform distribution; we find the optimal thresholds for each set, and then find the average optimal threshold as a function of an animal's order in the set of fighting abilities. To find the optimal thresholds for a given set of fighting abilities, we turn the difference in fighting abilities between each pair into the difficulty of the decision they have to make ($c$).  For an initial set of thresholds, we find $U_{ij}$ for each animal $i$ in each of its decisions and then average $\langle U_{ij}\rangle_j$ across all the animals with which it is engaged in a decision process.  We then allow each animal to choose a threshold that optimizes $\langle U_{ij}\rangle_j$ with respect to the rest of the group's thresholds and we iterate these choices until no animal chooses a new threshold.  

\subsection{Collective computation }
We are interested in how the consensus about the value of each individual emerges out of the decision process.  (In the social system, an animal's social power depends on the consensus in the group about its fighting ability \cite{Brush:2013fk,Flack:2004oq,Flack:2006uq}.)  Given an interaction network, there are many ways to measure the consensus present in the group about each individual's value \cite{Brush:2013fk, Flack:2006uq}. These formalisms assign a consensus score to each node in the network (interpreted as a power score in the social system).  In the following we consider four  consensus formalisms.  The first and simplest is simply the number of nodes sending decisions to each animal (number of signalers).  The second is the number of decisions received by each node, which is a finer measure than the first.  The third is the entropy of the distribution of the number of decisions sent to each individual, which measures gives a coarse measurement of how uniformly all other animals in the group behave with respect to a focal individual.  The fourth is the eigenvector centrality of the signaling network, which measures how central each node is in the global structure of the network.  For more details see \cite{Brush:2013fk}. 

To use these measures, we need to construct an interaction network between individuals in the group.  For each random set of fighting abilities, we let the animals optimize their thresholds, which give the probability that each pair will reach either decision and the expected time it will take.  We use these probabilities to generate a set of decisions between all pairs.  We use the convention that a decision is sent from $i$ to $j$ if in their decision $j$'s preference prevailed.  (In the social system, $i$ sends a subordination signal to $j$ to communicate his agreement to be subordinate.) To incorporate the time it takes for a decision to be reached and allow for multiple decisions to be sent, we say that $i$ sends $j$ a number of decisions equal to $1$ minus the expected decision time.  The decision network is then formed such that the edge from $i$ to $j$ is the number of signals sent from $i$ to $j$.  For many random sets of fighting abilities and for each consensus formalism, we can find the mutual information between the consensus scores and the true values and  the average skewness of the set of consensus scores.

\section{Results}
\subsection{Decision making is as accurate without a third party arbiter. }
We compare the decision making process in the full two-dimensional system and in a reduced one-dimensional system to see whether decisions are made more accurately or quickly in one or the other.  To make the systems directly comparable, we assume in both cases that the thresholds are symmetric, i.e. $T_1=T_2$.  We find that the two-dimensional decision is as accurate as the one-dimensional decision.  That is, for a given expected time to reach a decision, the two-dimensional decision will reach the correct decision with the same probability.  Accuracy decreases as leak rates ($\ell$) become higher, but increases when the strength of the input ($c$) is higher.

\subsection{The average accuracy in a group of stubborn individuals is higher than in a group of accurate individuals. }
The best measure of consensus depends on the accuracy of the decisions, so we address accuracy before moving on to discuss consensus. The Nash equilibrium thresholds for a pair of individuals depend on whether the individuals are minimizing error rate, maximizing probability of their preference, or minimizing decision time.  The pair can make the most accurate decision if the weaker individual chooses a low threshold and the strong individual chooses a high one, so if only error rate matters ($w_1=1$, $w_2=0$, $w_3=0$), those will be the Nash  thresholds.   If only preference matters ($w_1=0$, $w_2=0$, $w_3=1$), there is no incentive for the individuals to stop accumulating evidence (fighting, in the social case) so both individuals wait until the other gives up and the Nash  thresholds are both high.  If only decision time matters ($w_1=0$, $w_2=1$, $w_3=1$), both individuals have an incentive to set their thresholds low and reach a decision quickly, whatever that decision may be (Figure \ref{nasheq}).   

The accuracy with which a pair using Nash thresholds can reach a decision is highest when only error rate matters ($w_1=1$) and lowest when only decision time matters ($w_2=1$).  When waiting costs are low, accuracy decreases as the weight given to preference increases (Figure \ref{nasheq}).  It makes sense that as the individuals prioritize preference over error rate, they make increasingly inaccurate decisions.  For sufficiently high waiting costs, however, the Nash thresholds do not depend on the tradeoff between error rate and preference, so neither does the accuracy for a pair using Nash thresholds.  In other words, once waiting costs are high, a pair of individuals minimizing error rate and a pair each of whom maximizes the probability of reaching his preference will reach a decision with the same accuracy.

Prioritizing preference at the expense of error rate has a different effect as soon as the individuals are in a group with more than two members.  In a group, an individual's position in the group affects how it makes the tradeoff between error rate, preference and decision time.  If the individuals value error rate, as soon as any waiting costs are introduced individuals at the bottom of the group lower their thresholds because in so doing, they make much faster decisions without losing much accuracy.  On the other hand, if the individuals value preference and waiting costs are introduced, individuals at the bottom of the group will keep their thresholds higher because they can increase their chances of receiving a decision, even though it costs them time (Figure \ref{groupeq}).  

When individuals in the bottom of the group have slightly higher thresholds and wait slightly longer to make a decision, the accuracy of decisions between individuals both in the bottom of the group increases.  Even though the accuracy between two individuals in the top of the group is not strongly affected by this tradeoff and the accuracy between an individual in the bottom and an individual in the top decreases slightly, the net effect is that the average accuracy of all pairs in the group increases (Figure \ref{groupeq}).  For every measure of consensus, the mutual information between the consensus scores and the true values increases with average pairwise accuracy.  Thus, the information content of the consensus scores is also slightly higher when the individuals minimizes preference rather than error rate.

\subsection{Global network structure provides the most information when accuracy is high but imperfect. }
When pairwise decisions are on average quite accurate, the number of decisions received is the most informative about the underlying values (Figure \ref{bestmetric}).  This makes sense since when each edge in the decision network accurately reflects the difference in value between individuals, the number of edges received is informative about an individual's position in the group.  When the pairwise decisions are less accurate, global structure of the decision network provides information about values that the individual relationships do not, so eigenvector centrality is the measure that is the most informative about values.  

The number of signalers consistently overestimates individuals' value.  When accuracy is fairly high, this bias makes it uninformative about value.  However, when accuracy is quite low, this consistent bias actually make the number of signalers more informative than measures whose errors are less predictable. When accuracy is lower still, none of the measures are very informative, but entropy correctly gives the lowest individuals low scores, giving it an edge over the other measures.

\subsection{The skewness of the power distribution is maximized when decisions are moderately accurate. }
For each measure of consensus in the decision network, we find the average skewness of the distribution of consensus scores of a group using optimal thresholds, as they depend on optimization weight.  We find that for all measures skewness is maximized at intermediate waiting costs and does not depend strongly on the tradeoff between error rate and preference (Figure \ref{skewness}). (Results for number of signalers are shown in Figure \ref{skewness} and others are similar).  When waiting costs are low and accuracy is high, the decisions accurately represent the individuals' true  abilities so the distribution of number of signalers accurately represents the distribution of abilities, which is not very right-skewed.  When waiting costs are high and accuracy is low, all individuals receive decisions from a similar number of others, giving a distribution that is quite uniform and not right-skewed.  At intermediate waiting costs, the decisions sent to individuals with low to middle abilities are very noisy so that the individuals in the bottom and middle of the group receive signals from similar numbers of individuals.  However, all individuals make accurately decisions with the top few individuals, giving them high scores, resulting in a right-skewed distribution.


\subsection{Decisions in a group take longest between individuals with similarly high abilities. }
Difficult decisions tend to (but do not always) take longer than easier decisions.  In a social system, the difficult of a decision increases as a pair becomes more similar.  In a group of decision makers, the absolute value of two individuals, as well as the difference in their values, affects how quickly they can make a decision.  When waiting costs are low, the pairs that take the longest to reach a decision are those with similar fighting abilities, but pairs with different abilities also take a fairly long time.  When waiting costs are high, all pairs reach decisions quickly.  At intermediate costs, most pairs can reach a decision quite quickly, except those who have similar and high abilities (Figure \ref{groupeq}).  Pairs with similar and high abilities always take as long or longer to make a decision than any other pairs do.
 

\section{Discussion}

We derive a pair of stochastic differential equations that describe how two individuals accumulate evidence from a noisy environment.  The model can be equally well applied to the firing rates of neural populations observing a visual stimulus and the beliefs of two monkeys about their relative dominance based on their fighting history.   We first compare the simplified version of the model that is frequently used to describe the neural system and the full version we need to describe the social system.  We then consider a population of individuals using this model to make decisions to investigate the best way of making a collective computation, how to improve the accuracy of this computation and how the shape of the power structure in the social system depends on the accuracy of decisions.  Finally, we find a model output that is comparable to empirical observations.

Either the absolute value of the decision variables or the difference in their values can determine the outcome of the decision.  We find that, for a given decision time, the accuracy of the decision does not depend on which of these mechanisms is used.  In order for the difference in variables to be used, a third party arbiter needs to be present to evaluate the value of each decision variable and find their difference.  In the brain, it might be the case that there is a third neural population whose activity depends on the two populations gathering external evidence, but in a social group, there is not a third party informing how a pair of animals should establish their subordination-dominance relationship.  The fact, then, that the model does not depend on the existence of this third party arbiter means that it can be equally well applied whether or not it is present.

The decisions between pairs of individuals give rise to a network of decisions between all members of a group. A group of individuals will have some degree of consensus about the status of each individual. This consensus is the result of a collective computation that depends on individual behaviors.  There are many different ways of measuring this consensus and each represents a different way of performing the collective computation \cite{Brush:2013fk,Flack:2006uq}. When the accuracy of pairwise decisions is relatively high but imperfect, then a global metric like eigenvector centrality is the most informative about the true states of the nodes. When pairwise accuracy is quite low, then a coarse measure like the number of signalers or the entropy of decisions received outperforms a finer measure like the number of decisions received.

As network scientists, if we are presented with an interaction network, we would like to know how to measure the consensus present in the network about each node.  If we have a sense of the accuracy with which the edges reflect true differences in the states of the nodes, this result gives a rule of thumb for how to pick a measure of consensus. As members of a social group about which they would like to have information, the monkeys may use these measures (or approximations of them) to estimate their own and their peers' abilities. In previous work, we found that both eigenvector centrality and measures of the number of decisions received produced scores that were informative about animals' functional behavior in a group of pigtailed macaques.  This may be informative about the optimization weights the animals in that group are using.  If so, it would suggest that decision time is less important than a combination of error rate and the probability of being dominant. If animals in different species do prioritize fighting costs and the benefits from being dominant (i.e. decision time and probability of preference)  differently, we might expect to find that those animals use different properties of their social networks to estimate the power structure of the group.  

Individuals in biological systems are likely to be selfish and stubborn, both in order to maximize their own welfare and because prioritizing accuracy requires knowing which the ``right'' answer is.  The accuracy of the collective computation depends on how the individuals make the tradeoff between personal preference and accuracy, regardless of which measure is used to make the computation.  We expected to find that individuals valuing their preference at the expense of the correct output would tend to make decisions that were less accurate.  In a pair, this holds true.  However, when there is a group of individuals all making this tradeoff, valuing preferences over accuracy improves the accuracy with which individuals in the bottom of the group resolve their differences, increasing the average accuracy of the whole group. This overall accuracy translates into a more accurate collective computation.   

Usually only two neural populations are included in models of neural decision making (although see XXX).  Further, it is usually assumed that neural populations in the brain value accuracy, since the whole organism receives a benefit from making a correct decision in a short time.  But it is possible that different neural populations receive different rewards from making different decisions, regardless of which decision is the ``correct'' one.  Only by considering a group of decision makers do we find the surprising result that the accuracy of a collective computation can be improved by introducing conflicting interests.  This might suggest that in situations where a group of neural populations are recruited to make a decision, we could expect to find that they have different preferences, rather than all valuing accuracy. Our result also has interesting implications for designing networks whose properties we would like to use to make computations.

The skewness of the power structure that results from this collective computation in social groups of macaques has important functional consequences \cite{Flack:2004oq,Flack:2006fk}. We find that for most measures of power the skewness of the distribution of power scores is maximized at intermediate waiting costs.  In our data, we observe a right-skewed distribution of power \cite{Brush:2013fk,Flack:2006uq}.  To the extent that our model recapitulates the empirical system, this would suggest that waiting costs are neither the only priority nor are they ignored completely.

Different species of macaque have stereotypical power structures with different amounts of skewness \cite{Flack:2004oq,Preuschoft:2004ly,Waal:1985fk}.  One explanation might be that the distribution of fighting abilities is different from species to species, for instance if there is more or less variation in body size.  However, our model suggests that even if the underlying distribution of fighting abilities are identical, the priorities given to preference, error rate, and waiting costs can affect the distribution of power.  The benefit of having a partner agree to be subordinate, the benefit of reaching the ``correct" agreement, and the costs of fighting may vary from species to species, causing variation in the shape of the power structure.

In a more complicated model, the ``aggressiveness'' of animals moving in a spatially explicit area affected the shape of the dominance hierarchy \cite{Hemelrijk:2011fk}.  While the mechanisms of that model are quite different, ``aggressiveness'' could be argued to be similar to disregarding fighting costs and prioritizing preference.  Neither the authors of that work nor we found that a difference in the underlying distribution of fighting abilities is required to change the distribution of dominance or power.  In other words, in both models, the collective computation that results in a power structure depends more on how the individuals interact and collect information than on the distribution of fighting abilities. 

It is difficult to assess whether decisions in empirical systems are being made accurately, but it is easier to measure how long they take.  In a group, each pair of individuals experiences the difference in their abilities, but their absolute positions within the group also matter.  In data from a captive population of macaques, we observe that pairs of animals with high abilities reach agreements about their relative dominance but that pairs of animals with low abilities sometimes do not reach such agreements (JC Flack, unpublished data).  In our model, decisions between pairs who have similar and high abilities always  take as long or longer than decisions between any other pairs.  This discrepancy indicates that our simple model is missing a level of social complexity that could explain this empirical pattern.  

There are (at least) two modifications to the model that we expect would produce results closer to the empirical observations.  First, in the model, the rates at which animals fight each other do not depend on the abilities of the animals.  However, it is likely that animals with lower abilities are less mobile and encounter their peers at a lower rate than animals with higher abilities who are more free to range throughout the group.  In the model, this heterogeneity in encounter rate would make the decisions between animals with low encounter rates take longer.  Second, in the model, all animals value preference, error rate, and waiting costs equally.  However, it is likely that the benefits from receiving a subordination signal from a partner and the costs of fighting depend on both animals' abilities.  If animals with low ability  do not value an agreement with other animals with similar abilities, there would be less incentive for them to reach an agreement.  These types of heterogeneity would make our model more biologically realistic when applied to the social system, but without them it is general enough to be applied to a number of systems in which collective computations are being performed.  

We consider two systems, a neural and a social, and our model reduces to previously studied ``war of attrition'' games in the game theory literature when the abilities of the two individuals are equal.  The similarities between these three frameworks-- neural decision making, social decision making, and game theory-- suggest that there are common principles of decision making through conflict that are applicable to a number of systems. Conflict and strategy are not usually ascribed to the neural model, and the war of attrition is not usually thought of as a process through which the pair of competitors reaches a decision about an external truth.  Our work is a first step toward unifying these different frameworks and better understanding the importance of conflict and strategy in collective computation.
%%other applications?

\begin{figure}[ht]
\includegraphics[]{pairwise_accuracy.pdf}
\includegraphics[]{nasheq_thresholds.pdf}
\caption{\label{nasheq} The accuracy of a pair using Nash equilibrium thresholds decreases as the weight given to decision time increases.  (a) In the upper panel, the color indicates the accuracy of a decision made by a pair making a difficult decision ($c=.55$) using Nash equilibrium thresholds, as a function of the optimization weights, $w_1$, $w_2$, $w_3$.  In the lower left corner of the simplex, only error rate matters ($w_1=1$).  In the upper corner, only decision time matters ($w_2=1$).  In the lower right corner, only preference matters ($w_3=1$). Accuracy decreases as $w_2$ increases but is not greatly affected by a tradeoff between $w_1$ and $w_3$. In (b)-(g) we show how the Nash equilibrium thresholds depend on the difficulty of the decision ($c$). The optimization weights for each panel are indicated in the simplex with the corresponding letter.  }
\end{figure}

\begin{figure}[ht]
\includegraphics[width=\textwidth]{groupaccuracy_heatmap.pdf}
\includegraphics[width=\textwidth]{groupeq_thresholds.pdf}
\caption{\label{groupeq}   The accuracy of a group using optimal thresholds decreases as the weight given to decision time increases.  In the upper panels, the color indicates the average accuracy of the decisions between individuals in the bottom quartile (a) and the average accuracy of the whole group (b) using optimal thresholds, as a function of the optimization weights, $w_1$, $w_2$, $w_3$.  In the lower left corner of the simplex, only error rate matters ($w_1=1$).  In the upper corner, only decision time matters ($w_2=1$).  In the lower right corner, only preference matters ($w_3=1$). Both bottom-quartile and total accuracy decrease as $w_2$ increases, and the increase in bottom-quartile accuracy as $w_3$ increases drives a slight increase in total accuracy.  In (c)-(h) we show how the group-context optimal thresholds (top row) and decision time for each pair (bottom row) depends on the true order of value where $1$ is the strongest individual and $20$ is the weakest. The optimization weights for each panel are indicated in the simplex with the corresponding letter.  For low waiting costs (c and d), it takes longest for pairs with similar values to reach a decision.  For slightly higher waiting costs (f and g), it takes longer for pairs with similar and high values to reach a decision.}

\end{figure}

\section{Figures}
\begin{figure}[ht]
\includegraphics[width=\textwidth]{mostinformative_heatmap.pdf}
\caption{\label{bestmetric} The best method to use for measuring consensus in the decision network depends on how accurate decisions are on average.  When decision are very accurate or very inaccurate, measures of the number of decisions received are most informative.  When accuracy is slightly lower, eigenvector centrality of the decision network is most informative.  When accuracy is slightly lower again, the number of signalers is most informative.  When accuracy is lower still, the entropy of decisions received is most informative.  In the lower left corner of the simplex, only error rate matters ($w_1=1$).  In the upper corner, only decision time matters ($w_2=1$).  In the lower right corner, only preference matters ($w_3=1$).}
\end{figure}


\begin{figure}[ht]
\includegraphics[width=\textwidth]{skewness_heatmap.pdf}
\caption{\label{skewness} The average skewness of the distribution of the number of signalers is maximized at intermediate waiting costs. In the lower left corner of the simplex, only error rate matters ($w_1=1$).  In the upper corner, only decision time matters ($w_2=1$).  In the lower right corner, only preference matters ($w_3=1$).}
\end{figure}


\begin{table}[ht]
\centering
\caption{\label{variables}{\bf  Variables and interpretations in neural and social systems.} }
\ra{1.3}
\begin{tabular}{@{}lllll@{}}
Variable & Interpretation & Neural &   Social \\
\cmidrule{1-4} 
& input & dots moving left or right & fights won or lost
\\$c$ & strength of input & coherence of dots & prob. of stronger animal winning
\\$X_1,X_2$ & decision variables &  firing rates of neural populations & opinions about relative dominance
\\ $w_1$ & error rate weight & reward from being ``right" & reward from being ``right"
\\ $w_2$ & decision time weight & penalty for taking a long time & costs of fighting
\\ $w_3$ & prob. of preference weight & ? & benefit from receiving signal
\\ & decision & subject indicates left or right & one animal emits subordination signal
\\ & correct decision & subject chooses correct direction & weaker animal signals
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{\label{differences}{\bf  Comparison of models applied to neural and social systems.} Differences are highlighted in red.}
\ra{1.3}
\begin{tabular}{@{}lllll@{}}
& \multicolumn{2}{c}{Neural} &  Social \\
\cmidrule{2-3} \cmidrule{4-4} 
dimensionality & $1$  && $2$
\\decision & difference hits a threshold  && \fcolorbox{red}{white}{one var. hits a threshold}
\\ optimality criterion &  reward from being ``right" && reward from being ``right"
\\ & decision time && decision time
\\ & && \fcolorbox{red}{white}{reward from  receiving signal}
\\optimization depends on & input strength && input strength
\\ & noise && noise
\\ & leak rate && leak rate
\\ & && \fcolorbox{red}{white}{other animal's threshold}
\end{tabular}
\end{table}

\pagebreak
\section{Appendix}

\subsection{Derivation of PDEs for waiting time and accuracy \label{pdes_deriv}}

\pagebreak
\nocite{*}
\bibliographystyle{plain}
\bibliography{signaling_model}

\end{document}


